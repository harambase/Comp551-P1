import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GroupKFold
from sklearn.model_selection import KFold
from Naive_Bayes import NaiveBayes
from Project1_data import *

def k_fold_validation_acc(class_labels,k,X_train,y_train,ld):
	cv_acc=0
	NB=NaiveBayes(class_labels)
	l=np.arange(len(y_train))

	kf=np.array_split(l,k)

	for i in range(k):
		train=np.array([])
		test=kf[i]
		for j in range(k):
			if j is not i:
				train=np.concatenate((train, kf[j]), axis=None)

		test = test.astype(int)
		train = train.astype(int)

		NB.fit(X_train[train],y_train[train],ld)
		y1=NB.predict(X_train[test],ld)
		cv_acc=cv_acc+NB.evaluate_acc(y_train[test],y1)

	cv_acc=cv_acc/k
	return cv_acc


acc=[]
X_train,y_train=data_adult("adult.data",whether_One_hot_coding=False)
X_test, y_test = data_adult("adult.test",whether_One_hot_coding=False)

a_range=np.arange(0.1,2,0.1)
size_ = [200, 1000, 5000, 10000, 20000, 30161]

# for s in size_:
# 	acc_sub=[]
# 	X_train_sub=X_train[0:s,:]
# 	y_train_sub=y_train[0:s]
# 	for a in a_range:
# 		ld=[-1,a,-1,a,-1,a,a,a,a,a,-1,-1,-1,a]
# 		acc_sub.append(k_fold_validation_acc([0,1],5,X_train_sub,y_train_sub,ld))
# 	print(acc_sub)
# 	acc.append(acc_sub)

# print(acc)
# acc=[[0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577], [0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577], [0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577], [0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577], [0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577], [0.8272994441271504, 0.8272994441271504, 0.8272662876284766, 0.8272331366256589, 0.8272994441271504, 0.8272994441271504, 0.8272662931243324, 0.8272331366256587, 0.8271999801269849, 0.8271336726254935, 0.8271668236283114, 0.8271336726254935, 0.8271336726254935, 0.8271336781213494, 0.8271005216226757, 0.8271005216226757, 0.8270673651240019, 0.8271005216226757, 0.8270673706198577]]
acc=[[0.8150000000000001, 0.82, 0.82, 0.8150000000000001, 0.8150000000000001, 0.8150000000000001, 0.82, 0.8150000000000001, 0.8099999999999999, 0.8049999999999999, 0.8049999999999999, 0.8049999999999999, 0.8, 0.8049999999999999, 0.8, 0.8, 0.8099999999999999, 0.8099999999999999, 0.8099999999999999], [0.8280000000000001, 0.8280000000000001, 0.8260000000000002, 0.825, 0.825, 0.826, 0.826, 0.825, 0.8240000000000001, 0.8230000000000001, 0.8219999999999998, 0.8230000000000001, 0.8230000000000001, 0.8230000000000001, 0.8219999999999998, 0.8240000000000001, 0.8240000000000001, 0.8230000000000001, 0.8219999999999998], [0.8202, 0.8203999999999999, 0.821, 0.8211999999999999, 0.8211999999999999, 0.821, 0.8206, 0.8206, 0.8202, 0.8197999999999999, 0.8197999999999999, 0.8193999999999999, 0.8196, 0.8196, 0.8197999999999999, 0.8197999999999999, 0.8201999999999998, 0.8201999999999998, 0.8203999999999999], [0.8279, 0.8279, 0.8279, 0.8278000000000001, 0.8279, 0.8276999999999999, 0.8276999999999999, 0.8276, 0.8276999999999999, 0.8275, 0.8272999999999999, 0.8273999999999999, 0.8273999999999999, 0.8275, 0.8276, 0.8276, 0.8273999999999999, 0.8273999999999999, 0.8273999999999999], [0.8288, 0.8288, 0.8288499999999999, 0.8288499999999999, 0.8289, 0.8288499999999999, 0.82865, 0.82865, 0.8286000000000001, 0.82865, 0.82865, 0.8287000000000001, 0.82875, 0.82875, 0.8286999999999999, 0.8288, 0.82875, 0.82875, 0.82875], [0.827293689966018, 0.8273268464646918, 0.827293689966018, 0.827293689966018, 0.8272936954618739, 0.8272605444590561, 0.8272605444590561, 0.8271942314617086, 0.8271942314617086, 0.8271610749630348, 0.8271610694671789, 0.8271279129685052, 0.8271279129685052, 0.8270947564698314, 0.8270947564698314, 0.8270284434724839, 0.8270284434724839, 0.8270284434724839, 0.8270615999711577]]
for i in range(len(acc)):
	plt.plot(a_range,acc[i], linewidth=1,marker='o', linestyle='dashed', label='size=%s'%size_[i])
	

plt.xlabel("Smoothing parameter",fontsize = 11)
plt.ylabel("Cross validation accuracy")
plt.yticks(np.arange(0.7,0.95,0.1))
plt.legend(loc='lower right')
plt.show()

